<!doctype html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <title>Blog Article Copenhagen</title>
    <meta name="robots" content="noindex, nofollow">
    <meta name="author" content="Patrick Hund">
    <meta name="description" content="Blog Article Copenhagen">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" href="css/main.css">
</head>
<body>
<nav class="navigation">
    <a href="./index.html">part 1</a> |
    <a href="./part2.html">part 2</a> |
    <a href="./part3.html">part 3</a> |
    <a href="./part4.html">part 4</a><br>
    <a href="#">top</a> |
    <a href="#bottom">bottom</a>
</nav>
<div class="autoreload">
    <label for="autoreload">
        <input type="checkbox" id="autoreload">
        auto reload
    </label>
</div>

<div class="status">
    &#128679; Work in progress
</div>

<article>

    <!-- TITLE -->

    <h1>Node.js and ES6 Instead of Java – A War Story</h1>
    <p><small>by <a href="http://twitter.com/wiekatz">Patrick Hund</a></small></p>

    <!-- TEASER -->
    <h2>Part II: The Joy and Pain of Test Driven Development</h2>

    <p><img src="./data/mediapool/from-the-trenches_709x255.png" alt="From the trenches" width="709" height="255"></p>

    <p>We created a Node.js web app from scratch within 9 weeks that now serves 10.81 million visitors each month*. We used the latest and greatest incarnation of JavaScript – ECMAScript 2015, a.k.a. ES6 – for the backend and frontend alike. We spent late nights coding in gleeful frenzy, stepped into pitfalls, moaned about WTFs, scaled the dizzy heights of asynchronicity. This is the second part of our story.</p>

    <p><small>* AGOF Digital Facts 2015-06</small></p>

    <p>If you missed part I, read up on it here on the <a href="http://www.technology-ebay.de/the-teams/mobile-de/blog/nodejs-es6-war-story">eBay Technology Blog Europe.</a></p>

    <!-- ARTICLE START -->

    <h2>What Joy? What Pain?</h2>

    <p>Hi, I'm Patrick, software engineer. My team and I work for <a href="http://www.mobile.de">mobile.de</a>, which is Germany's biggest online marketplace for cars and other vehicles.</p>

    <p>In the second part of my series, I'll focus on automated tests for the backend.</p>

    <p>When I started with the backend code for our new application, working with Node.js and the <a href="http://expressjs.com/">Express framework</a> was still mostly <em>terra incognita</em> for me. I had written a couple of Grunt tasks and an import script to fetch data from an API, but never a fully fledged webapp, at least not in JavaScript.</p>

    <p>I had written web apps in Java back in the days before I moved from backend to frontend. Building on that experience and looking at the mess the old mobile.de home page web app had become over the years, one thing was crystal clear:</p>

    <p><b>You cannot write maintainable code without proper unit test coverage.</b></p>

    <p>If you have proper test coverage, you can easily refactor your code without having to fear to break something without being aware of it. This has happened to me countless times. I'll make a wild guess and assume it has happened to you, too. &#128522;</p>

    <div class="placeholder">
        cartoon
    </div>

    <p>There's a German saying for this: “Mit dem Arsch einreißen was man mit den Händen aufgebaut hat.” (tearing down with your ass what you've built up with your hands)</p>

    <p>Automated tests are the only way I know of to obviate this phenomenon.</p>

    <p>The safety net of good test coverage is even more important in JavaScript than in Java, as JavaScript lacks typ safety, something I'm starting more and more to resent (yeah, I know, there's <a href="http://www.typescriptlang.org/">TypeScript</a>, I haven't gotten around to trying that yet).</p>

    <p>With a good test setup that runs your tests automatically as you write your code, you can concentrate intensely on solving the problem at hand, without being distracted by things like reloading the page in the browser or restarting the server. You can deep dive <a href="http://psygrammer.com/2011/02/10/the-flow-programming-in-ecstasy/">into the zone</a>. To me, this is joy indeed.</p>

    <h3>So What's Not to Like? What's the Pain?</h3>

    <p>Well, on the mobile.de home page project, I spent more time writing tests and stubs and mocks and fixtures and what not than I spent writing the actual production code. It was maddening sometimes to write tests for things like asynchronous calls, promises, timeouts, etc. The urge to just let it slip and not write a test for some module was sometimes overwhelming, especially given the time constraints we had. I'm very proud to say that my team mates and I resisted the temptation in most cases.</p>

    <h2>Tasty Mocha</h2>

    <div class="placeholder">
        mocha, sinon, chai logos
        picture of mocha cup in blog folder
    </div>

    <p>
        I had previously worked with <a href="http://jasmine.github.io/">Jasmine</a>, which is great for testing frontend JavaScript code, especially if you use jQuery, since there is a great lib <a href="https://github.com/velesin/jasmine-jquery">jasmine-jquery</a> that allows you to create HTML fixtures to test jQuery DOM interaction easily.
    </p>
    <p>
        My colleague <a href="http://twitter.com/jonykrause">Jonathan</a> proposed to use <a href="https://mochajs.org/">Mocha</a> instead of Jasmine for testing our Node.js backend code. Since I'm always up for trying out new stuff, naturally, I went for it.
    </p>
    <p>
        Mocha's syntax is very similar to Jasmine's. You formulate your test cases as a series of nested <em>describe</em> function calls with an <em>it</em> function call containing your assertion:
    </p>

    <iframe src="http://pahund.github.io/blog-article-copenhagen/examples/mocha-chai-bdd" frameBorder="0"  width="100%" height="220" scrolling="no" seamless></iframe>

    <p>Using the assertion library <a href="chaijs.com">Chai</a>, you can write nice readable test code in the style of <a href="https://en.wikipedia.org/wiki/Behavior-driven_development">behavior-driven development</a> (BDD): <em>codeQuality.should.equal("awesome")</em></p>
    <p>
        The console output of this little example looks like this:
    </p>

    <p><img src="./data/mediapool/example-mocha-chai-bdd-output_300x216.png" alt="Mocha test output" width="300" height="216"></p>
    <p><small><a href="https://github.com/pahund/blog-article-copenhagen/tree/master/demos/mocha-chai-bdd">(full code example available on GitHub)</a></small></p>

    <div class="placeholder">
        Wallaby
        Robot
    </div>

    <h2>Writing Testable Code</h2>

    <p>In contrast to Java classes, Node modules are singletons by nature, if you use them in multiple places, you always get the same instance of the module with the same scope.</p>

    <p>When I got started coding the new mobile.de home home page's backend, I found this really convenient and elegant. “No need to write all that boilerplate code with class instantiation and what not like in Java,” I thought.</p>
    <p>Here's a (very simplified) example of a node module <a href="https://github.com/pahund/blog-article-copenhagen/tree/master/demos/testable-code-bad-example/makes.js">makes.js</a> that provides a list of car or motorbikes makes, which can be used for populating a dropdown menu on a search form:</p>

    <iframe src="http://pahund.github.io/blog-article-copenhagen/examples/unit-test-bad-makes.html" frameBorder="0"  width="100%" height="190" scrolling="no" seamless></iframe>

    <p>The module imports a configuration module <em>config.js</em>, gets a path to a <a href="https://github.com/pahund/blog-article-copenhagen/tree/master/demos/testable-code-bad-example/makes.json">local JSON file with make data</a>, imports this with require and exposes a get method that accepts a segment (“car” or “motorbike”) for getting a list of makes.</p>

    <p>The config module <a href="https://github.com/pahund/blog-article-copenhagen/tree/master/demos/testable-code-bad-example/config.js">config.js</a> looks like this:</p>

    <iframe src="http://pahund.github.io/blog-article-copenhagen/examples/unit-test-bad-config.html" frameBorder="0"  width="100%" height="95" scrolling="no" seamless></iframe>

    <p>And, finally, this is the Mocha test suite <a href="https://github.com/pahund/blog-article-copenhagen/tree/master/demos/testable-code-bad-example/test.js">test.js</a>:</p>

    <iframe src="http://pahund.github.io/blog-article-copenhagen/examples/unit-test-bad-test.html" frameBorder="0"  width="100%" height="300" scrolling="no" seamless></iframe>

    <p>Running <em>npm test</em> on the console gives us this output:</p>

    <p><img src="./data/mediapool/unit-test-bad-output_280x155.png" alt="Test output" width="280" height="155"></p>

    <p>What's wrong with this? <strong>It is not really a unit test!</strong> We are not only testing <em>makes.js</em>, we're also testing <em>config.js</em> and even <em>makes.json</em>. If <em>makes.json</em> is updated, it might break the test for <em>makes.js</em>. We only want the test to break if something in <em>makes.js</em> is changed, not some JSON file we don't care about.</p>

    <p>OK, so let's just create a mock for <em>config.js</em> in the <em>before</em> method and let that mock return the URL of a mockup JSON file with bespoke test data.</p>

    <p>But wait, how can I mock the config module? It is in the scope of the makes module the instant it is imported. The fact that the makes module is a singleton, as mentioned earlier, makes it quite hard to slip our testing fingers inside the module and switch the config to a mock.</p>

    <h3>“It's a Trap!”</h3>

    <p>What would <a href="https://www.youtube.com/watch?v=4F4qzPbcFiA">Admiral Ackbar</a> do? Certainly not what I did at this point. I stepped into the trap of refactoring my test code around a system that was hard to test because of my poor architecture choice.</p>

    <p>Here's a <em>slightly less crappy</em> version of <a href="https://github.com/pahund/blog-article-copenhagen/tree/master/demos/testable-code-slc-example/makes.js">makes.js</a>:</p>

    <iframe src="http://pahund.github.io/blog-article-copenhagen/examples/unit-test-slc-makes.html" frameBorder="0"  width="100%" height="185" scrolling="no" seamless></iframe>

    <p>The only difference to the previous version is that the <a href="https://github.com/pahund/blog-article-copenhagen/tree/master/demos/testable-code-slc-example/config.js">config module</a> now has a method <em>getPath</em> that gives us the path to the JSON file with the data. Using a method instead of a property allows us to mock the config module using <a href="http://sinonjs.org/">Sinon.JS</a>.</p>

    <p>There's only one problem: we still can't slip the mock to the makes module, because it is instantiated the instant it is loaded.</p>

    <p>To work around this, I used a small library named <a href="https://github.com/totherik/freshy">freshy</a>. <em>freshy</em> allows us to load a fresh instance of a module whenever we want, without getting the same instance over and over again from the npm cache. This way, we can load our makes module <strong>after</strong> the config mock has been created.</p>

    <p>The <a href="https://github.com/pahund/blog-article-copenhagen/tree/master/demos/testable-code-slc-example/test.js">slightly less crappy test</a> looks like this:</p>

    <iframe src="http://pahund.github.io/blog-article-copenhagen/examples/unit-test-slc-test.html" frameBorder="0"  width="100%" height="395" scrolling="no" seamless></iframe>

    <p>I'm mocking config before instantiating the makes module with freshy, it works – I was satisfied, and wrote many, many tests like this.</p>

    <h3>The Horror, the Horror</h3>

    <p>It turned out that outsmarting the npm cache was not such a great idea, especially when writing tests for asynchronous operations in this manner. It worked fine when running the tests locally, but when running them as part of our distribution build on Jenkins CI, we soon experienced builds that we're hanging and tests that failed with timeouts. It got so bad that at some point we were forced to actually disable our test suites to be able to deploy changes to production, without having to retrigger the build multiple times until it finally finished with green tests.</p>

    <h3>A Better Way</h3>

    <p>The hard learned lesson here is:</p>

    <p><img src="./data/mediapool/cross-stitch-testable_700x426.png" alt="Write testable code" width="700" height="426"></p>

    <p>We eventually refactored a lot of our modules to not be instantly available singletons, but provide an init method that instantiates the module.</p>

    <p>A revised version of the above example looks like this:</p>

    <iframe src="http://pahund.github.io/blog-article-copenhagen/examples/unit-test-good-makes.html" frameBorder="0"  width="100%" height="260" scrolling="no" seamless></iframe>

    <p><a href="https://github.com/pahund/blog-article-copenhagen/tree/master/demos/testable-code-good-example/makes.js">makes.js</a> now has an init method. The JSON data is only loaded when the init method is invoked, not immediately after the module was loaded.</p>

    <iframe src="http://pahund.github.io/blog-article-copenhagen/examples/unit-test-good-test.html" frameBorder="0"  width="100%" height="260" scrolling="no" seamless></iframe>

    <p>In <a href="https://github.com/pahund/blog-article-copenhagen/tree/master/demos/testable-code-good-example/test.js">test.js</a>, it is now much easier to mock <a href="https://github.com/pahund/blog-article-copenhagen/tree/master/demos/testable-code-good-example/config.js">config.js</a> to switch the JSON file to the <a href="https://github.com/pahund/blog-article-copenhagen/tree/master/demos/testable-code-good-example/test-makes.json">mock version</a>.</p>

    <h2>Measuring Test Coverage</h2>

    <p>
        To run the Mocha test suites and measure the code coverage, we use our build system, which is based on <a href="https://docs.npmjs.com/cli/run-script">npm script runners</a> that trigger various <a href="http://gulpjs.com/">Gulp</a> tasks. The tests are run with <em>npm test</em> or as part of the distribution package build that is run with <em>npm run dist</em>.
    </p>

    <p>
        For measuring the code coverage, we use <a href="https://github.com/gotwarlost/istanbul/">Istanbul</a>, the <a href="https://github.com/SBoudrias/gulp-istanbul">Istanbul plugin for Gulp</a> and <a href="https://github.com/douglasduteil/isparta/">Isparta</a>, which provides an instrumenter that makes it possible to measure code coverage on ES6 files that are transpiled through <a href="https://babeljs.io/">Babel</a> (we use Babel for both the backend and frontend).
    </p>

    <p>
        Instead of another sandbox example, let's take a peek at our actual production code, the Gulp task for running the backend JavaScript tests:
    </p>

    <iframe src="http://pahund.github.io/blog-article-copenhagen/examples/backend-mocha-gulp" frameBorder="0"  width="100%" height="830" scrolling="no" seamless></iframe>

    <p>
        Some things to note here:
    </p>
    <p>
        Take a look at the comments at the beginning of the file: <a href="https://github.com/sindresorhus/gulp-mocha/issues/86">gulp-mocha</a> and <a href="https://github.com/douglasduteil/isparta/issues/45 ">Isparta</a> have bugs that force us to use some workarounds. In my experience, this is fairly typical when working with npm modules. You have to embrace the fact that software is never perfect and accept it. The good news about open source software is that you can fix these bugs yourself by creating a pull request, or at least contribute by reporting the bugs. You quickly find workarounds on GitHub or <a href="http://stackoverflow.com/">Stack Overflow</a>, or have to pick some other solution for your problem. I've gotten in the habit of putting links to these issues in my code's comments and then revisit once in a while to see if the problem was fixed with a new version of the module.</p>
    </p>
    <p>
        The <em>istanbul.enforceThresholds</em> property makes the build fail when the code coverage drops below a specific percentage. We currently have this set to 84%. Since we have a <a href="https://github.com/dflourusso/pre-push">pre-push hook</a> that executes the tests before pushing to Git, this means you cannot push new code without proper unit tests. Needless to say, this can be annoying sometimes, but it helps a lot to keep our code clean. &#128522;
    </p>
    <p>
        Another important configuration detail is <em>includeUntested: true</em> (towards the end of the code example). If you don't set this, Istanbul will only measure the coverage of modules that actually have an accompanying unit test. Modules that don't have any tests at all are not included in the coverage report. I only found out about this a few weeks ago. Up until then, I had often bragged to people: “Yeah, you know. We have 98% test coverage.” After turning this option on, I found out it was actually just 84%.
    </p>
    <p>
        Here's a little video of our test build in action:
    </p>

    <p><iframe width="560" height="315" src="https://www.youtube.com/embed/w5OBYjd27hs" frameborder="0" allowfullscreen></iframe></p>

    <div class="placeholder">
        end section / summary / coming up next
    </div>

    <h2>Acknowledgements</h2>

    <ul>
        <li>Cross-stitch image made with <a href="https://photofunia.com/">Photofunia</a></li>
    </ul>

    <!-- ARTICLE END -->

</article>
<a name="bottom">&nbsp;</a>
<script src="js/main.js"></script>
</body>
</html>
